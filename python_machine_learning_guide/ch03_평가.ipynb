{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 03. 평가\n",
    "머신러닝 구성: 데이터 가공/변환, 모델 학습/예측, 평가(Evaluation) 프로세스로 구성  \n",
    "성능 평가 지표(Evaluation Metric): 모델이 분류인지 회귀인지에 따라 여러 종류로 나뉨  \n",
    "\n",
    "- 회귀: 대부분 실제값과 예측값의 오차 평균값에 기반  \n",
    "  ex) 오차에 절댓값을 씌운 뒤 평균 오차를 구하거나 오차의 제곱값에 루트를 씌운 뒤, 평균 오차를 구하는 방법\n",
    "      -> 기본적으로 예측 오차를 가지고 정규화 수준을 재가공하는 방법 (5장에서 다시 설명)\n",
    "- 분류: 일반적으로는 실제 결과 데이터와 예측 결과 데이터가 얼마나 정확하고 오류가 적게 발생하는가에 기반\n",
    "        단, 단순히 이러한 정확도만 가지고 판단할 경우 잘못된 평가 결과로 빠질 수 있음\n",
    "\n",
    "해당 장에서는 분류에 사용되는 성능 평가 지표에 관해 학습\n",
    "특히, 0과 1로 결정값이 한정되는 이진 분류의 성능 평가 지표에 관해 집중적으로 살펴볼 예정  \n",
    "0이냐 1이냐 혹은 긍정/부정을 판단하는 이진 분류에서는 정확도보다는 다른 성능 평가 지표가 더 중요시되는 경우가 많음\n",
    "\n",
    "- 분류의 성능 평가 지표\n",
    "  - 정확도(Accuracy)\n",
    "  - 오차행렬(Confusion Matrix)\n",
    "  - 정밀도(Precision)\n",
    "  - 재현율(Recall)\n",
    "  - F1 스코어\n",
    "  - ROC AUC\n",
    "  \n",
    "- 분류의 나눔\n",
    "  - 이진 분류: 결정 클래스 값 종류 유형에 따라 긍정/부정과 같은 2개의 결괏값만을 가짐\n",
    "  - 멀티 분류: 여러 개의 결정 클래스 값을 가지는 멀티 분류\n",
    "\n",
    "분류의 성능 지표는 특히 이진 분류에서 더욱 중요하게 강조됨  \n",
    "\n",
    "\n",
    "## 01. 정확도(Accuracy)\n",
    "- 정확도: 실제 데이터에서 예측 데이터가 얼마나 같은지 판단하는 지표  \n",
    "  $$ 정확도(Accuracy) = \\frac{예측 결과가 동일한 데이터 수}{전체 예측 데이터 수} $$\n",
    " \n",
    "정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표  \n",
    "단, 이진 분류의 경우 데이터 구성에 따라 ML 모델 성능을 왜곡할 수 있어서 정확도 수치 하나로만 성능을 평가하지 않음  \n",
    "\n",
    "**예시**\n",
    "2장의 타이타닉 예제 수행 결과를 보면 정확도의 한계를 볼 수 있음  \n",
    "ML 알고리즘을 적용한 후 예측 정확도 결과가 보통 80%대였지만, 탑승객이 남자인 경우보다 여자인 경우 생존 확률이 높았기 때문에 별다른 알고리즘 적용 없이 성별이 여자인 경우 무조건 생존, 남자인 경우 사망으로 예측 결과를 예측해도 비슷한 수치가 나올 수 있음  \n",
    "-> 성별 조건 하나만ㅇ로 결정하는 수준 낮은 알고리즘도 높은 정확도를 나타내는 상황이 발생할 수 있음  \n",
    "\n",
    "**추가 실습**\n",
    "사이킷런의 BaseEstimator 클래스를 상속받아 아무런 학습을 하지 않고, 성별에 따라 생존자를 예측하는 단순한 Classifier를 생성  \n",
    "(사이킷런은 BaseEstimator를 상속받으면 Customized 형태의 Estimator를 개발자가 생성할 수 있게 함)  \n",
    "- MyDummyClassifier 클래스: 학습을 수행하는 fit() 메서드는 아무것도 수행하지 않고, 예측을 수행하는 predict() 메서드는 단순이 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측하는 매우 단순한 Classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit() 메서드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict() 메서드는 단순히 Sex 피처가 1이면 0, 아니면 1로 예측\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0],1) )\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1 \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생성된 MyDummyClassifier를 이용해 타이타닉 생존자 예측 수행\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "## 머신러닝에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "## Label Encoding 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "## 앞에서 실행한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('data/titanic/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop(['Survived'], axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 활용해서 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순한 알고리즘으로 예측하더라도 데이터 구성에 따라 정확도 결과는 약 78.77%로 꽤 높은 수치가 나올 수 있음  \n",
    "-> 정확도를 평가 지표로 사용할 때는 신중할 필요가 있음  \n",
    "\n",
    "특히, 불균형한(imbalanced) 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 평가 지표가 아님  \n",
    "ex) 100개의 데이터가 있고 이 중 90개의 데이터 레이블이 0, 단 10개의 데이터 레이블이 1이라고 한다면 무조건 0으로 예측 결과를 반환하는 ML 모델의 경우라도 정확도가 90%가 됨  \n",
    "\n",
    "**MNIST 데이터 세트로 살펴보기**\n",
    "MNIST 데이터 세트를 변환해 불균형한 데이터 세트로 만든 뒤, 정확도 지표 적용 시 발생하는 문제 살펴보기  \n",
    "MNIST 데이터 세트는 0부터 9까지 숫자 이미지 픽셀 정보를 가지고 있으며, 숫자 Digit를 예측하는데 사용됨  \n",
    "사이킷런은 load_digits() API를 통해 MNIST 데이터 세트를 제공  \n",
    "\n",
    "원래 MNIST 데이터 세트는 레이블 값이 0부터 9까지 있는 멀티 레이블 분류를 위한 것이나, 이를 레이블 값이 7인 것만 True, 나머지 값은 모두 False로 변환해 이진 분류 문제로 바꾸어 실습  \n",
    "-> 전체 데이터의 10%만 True, 나머지 90%는 False인 불균형한 데이터 세트로 변형  \n",
    "\n",
    "- MNIST 데이터셋을 multi classification에서 binary classification으로 변경\n",
    "불균형한 데이터 세트에 모든 데이터를 False로, 즉 0으로 예측하는 classifier를 이용해 정확도를 측정하면 약 90%에 가까운 예측 정확도를 나타냄  \n",
    "아무것도 하지 않고 무조건 특정한 결과로 찍어도 데이터 분포도가 균일하지 않은 경우, 높은 수치가 나타날 수 있음  \n",
    "\n",
    "ex) step 1. 불균형한 데이터 세트와 Dummy Classifier 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 세트 크기만큼 모두 0값으로 만들어 변환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "# 사이킷런의 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "# digits 번호가 7번이면 True고, 이를 astype(int)로 1로 변환, 7번이 아니면 False고 0으로 변환\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2. 불균형한 데이터로 생성한 y_test 데이터 분포도를 확인하고 MyFakeClassifier를 이용해 예측과 평가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기: (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기:', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 predict() 결과를 np.zero()로 모두 0값으로 반환함에도 불구하고 450개의 테스트 데이터 세트에 수행한 예측 정확도는 90%  \n",
    "단지 모든 것을 0으로만 예측해도 MyFakeClassifier의 정확도가 90%로 유수의 ML 알고리즘과 비슷한 결과를 냄  \n",
    "\n",
    "-> 정확도 평가 지표는 불균형한 레이블 뎅터 세트에서 성능 세트로 사용해서는 안 됨  \n",
    "-> 정확도를 분류 평가 지표로 사용 시, 한계를 극복하기 위해 여러 가지 분류 지표를 함께 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 오차 행렬\n",
    "오차 행렬(confusion matrix, 혼동행렬): 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리는지(confused) 보여주는 지표  \n",
    "-> 이진 분류의 예측 오류가 얼마인지, 어떤 유형의 예측 오류가 발생하는지를 나타내는 지표  \n",
    "\n",
    "오차 행렬은 4분명 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매핑되는지를 나타냄  \n",
    "4분면의 왼쪽, 오른쪽을 예측된 클래스 값 기준으로 Negative와 Positive로 분류하고 4분면의 위, 아래를 실제 클래스 값 기준으로 Negative와 Positive로 분류하면 예측 클래스와 실제 클래스 값 유형에 따라 결정되는 TN, FP, FN, TP 형태로 오차 행렬의 4분면이 만들어짐  \n",
    "\n",
    "True/False: 예측값과 실제값이 같음/틀림, Negative/Positive: 예측 결괏값이 부정(0)/긍정(1)  \n",
    "- TN: 예측값을 Negative 값 0으로 예측, 실제 값도 Negative 값 0\n",
    "- FP: 예측값을 Positive 값 1로 예측, 실제 값은 Negative 값 0\n",
    "- FN: 예측값을 Negative 값 0으로 예측, 실제 값은 Positive 값 1\n",
    "- TP: 예측값을 Positive 값 1로 예측, 실제 값도 Positive 값 1\n",
    "\n",
    "사이킷런은 오차 행렬을 구하기 위해 confusion_matrix() API를 제공  \n",
    "정확도 예제에서 다룬 MyFakeClassifier의 예측 성능 지표를 오차 행렬로 표현해보기  \n",
    "(예측 결과인 fakepred와 실제 결과인 y_test를 confusion_matrix()의 인자로 입력해 오차 행렬을 confusion_matrix()를 이용해 배열 형태로 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력된 오차 행렬은 ndarray 형태  \n",
    "이진 분류의 TN, FP, FN, FP는 상단 도표와 동일한 위치를 가지고 array에서 가져올 수 있음  \n",
    "-> TN은 array[0,0]으로 405, FP는 array[0,1]로 0, FN은 array[1,0]으로 45, TP는 array[1,1]로 0에 해당  \n",
    "\n",
    "앞 절의 MyFakeClassifier는 load_digits()에서 target == 7인지 아닌지에 따라 클래스 값을 Ture/False 이진 분류로 변경한 데이터 세트를 사용해서 무조건 Negative로 예측하는 Classifier였고 테스트 데이터 세트의 클래스 값 분포는 0이 405건, 1이 45건  \n",
    "- TN: 전체 450건 데이터 중, 무조건 Negative 0으로 예측해서 True가 된 결과 405건\n",
    "- FP: Positive 1로 예측한 건수가 없으므로 0건\n",
    "- FN: Positive 1인 건수 45건을 Negative로 예측해서 False가 된 결과 45건\n",
    "- TP: Positive 1로 예측한 건수가 없으므로 0건\n",
    "\n",
    "TP, TN, FP, TN 값은 Classifier 성능의 여러 면모를 판단할 수 있는 기반 정보를 제공  \n",
    "이 값을 조합해 Classifier 성능을 측정할 수 있는 주요 지표인 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있음  \n",
    "\n",
    "cf) 정확도는 예측값과 실제 값이 얼마나 동일한가에 관한 비율만으로 결정  \n",
    "    -> 오차 행렬에서 True에 해당하는 값인 TN과 TP에 좌우됨\n",
    "- 정확도 = 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수 = $\\frac{TN + TP}{TN + FP + FN + TP}$  \n",
    "\n",
    "일반적으로 불균형한 레이블 클래스를 가지는 이진 분류 모델에서는 많은 데이터 중 중점적으로 찾아야 하는 매우 적은 수의 결괏값에 Positive를 설정해 1값을 부여, 그렇지 않은 경우는 Negative로 0값을 부여하는 경우가 많음  \n",
    "ex) 사기 행위 예측 모델: 사기 행위 Positive 양성, 1 / 정상 행위 Negative 음성, 0  \n",
    "    암 검진 예측 모델: 암이 양성일 경우 Positive 양성, 1 / 암이 음성일 경우 Negative 음성, 0  \n",
    "    \n",
    "불균형한 이진 분류 데이터 세트에서는 Positive 데이터 건수가 매우 작기 때문에 데이터에 기반한 ML 알고리즘은 Positive보다는 Negative로 예측 정확도가 높아지는 경향 발생  \n",
    "10,000건의 데이터 세트에서 9,900건이 Negative고 100건이 Positive라면 Negative로 예측하는 경향이 더 강해 TN은 매우 커지고 TP는 매우 작아짐  \n",
    "Negative로 예측할 때, 정확도가 높기 때문에 FN(Negative로 예측할 때 틀린 데이터 수)이 매우 작고, Positive로 예측하는 경우가 작기 때문에 FP 역시 작아짐  \n",
    "-> 정확도 지표는 비대칭한 데이터 세트에서 Positive에 관한 예측 정확도를 판단하지 못한 채 Negative에 관한 예측 정확도만으로도 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으킴  \n",
    "\n",
    "**정리**\n",
    "정확도는 분류(Classification) 모델의 성능을 측정할 수 있는 한 가지 요소  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 정밀도와 재현율\n",
    "정밀도&재현율: Positive 데이터 세트의 예측 성능에 조금 더 초점을 맞춘 평가 지표  \n",
    "앞서 만든 MyFakeClassifier는 Positive로 예측한 TP 값이 하나도 없기 때문에, 정밀도와 재현율 값이 모두 0  \n",
    "\n",
    "- 정밀도 = $\\frac{TP}{FP + TP}$  \n",
    "- 재현율 = $\\frac{TP}{FN + TP}$\n",
    "<br>\n",
    "\n",
    "- **정밀도: 예측값을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율**  \n",
    "  - 공식의 분모인 FP + TP: 예측을 Positive로 한 모든 데이터 건수 / 분자인 TP: 예측과 실제 값이 Positive로 일치한 데이터 건수\n",
    "  - Positive 예측 성능을 더욱 정밀히 측정하기 위한 평가 지표로 '양성 예측도'라고도 불림  \n",
    "<br>\n",
    "\n",
    "- **재현율: 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율**\n",
    "  - 공식의 분모인 TN + TP: 실제 값이 Positive인 모든 데이터 건수 / 분자인 TP: 예측과 실제 값이 Positive로 일치한 데이터 건수\n",
    "  - 민감도(Sensitivity) 또는 TPR(True Positive Rate)라고도 불림\n",
    "<br>\n",
    "\n",
    "정밀도와 재현율 지표 중, 이진 분류 모델의 업무 특성에 따라 특정 평가 지표가 더 중요한 지표로 간주될 수 있음\n",
    "- 재현율이 중요 지표인 경우: 실제 Positive 양성 데이터를 Negative로 잘못 판단할 시, 업무에 큰 영향이 발생하는 경우\n",
    "- 정밀도가 중요 지표인 경우: 실제 Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단 시, 업무상 큰 영향이 발생하는 경우\n",
    "<br>\n",
    "\n",
    "**정리**\n",
    "재현율과 정밀도 모두 TP를 높이는 데 초점  \n",
    "재현율은 FN(실제 Positive, 예측 Negative)를 낮추는 데, 정밀도는 FP를 낮추는 데 초점  \n",
    "-> 서로 보완적인 지표로 분류의 성능을 평가하는 데 적용되며 두 수치 모두 높은 것이 가장 좋은 성능  \n",
    "   (둘 중 어느 한 평가 지표만 매우 높고, 다른 수치는 매우 낮은 경우는 바람직하지 않음)  \n",
    "   \n",
    "ex) 타이타닉 예제\n",
    "오차 행렬 및 정밀도, 재현율을 모두 구해 예측 성능 평가하기  \n",
    "사이킷런은 정밀도 계산을 위해 precision_score()를, 재현율 계산을 위해 recall_score()를 API로 제공  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 간편히 적용하기: coufusion, matrix, accuracy, precision, recall 등 평가를 한 번에 호출하는 get_clf_eval() 함수 만들기\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {:.4f}\\n정밀도 : {:.4f}\\n재현율 : {:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 기반으로 타이타닉 생존자를 예측하고 confusion matrix, accuracy, precision, recall 평가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492\n",
      "정밀도 : 0.7742\n",
      "재현율 : 0.7869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('data/titanic/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size = 0.2, random_state = 11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도(Precision)에 비해 재현율(Recall)이 낮게 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 정밀도/재현율 트레이드오프\n",
    "분류의 결정 임곗값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있음  \n",
    "단, 정밀도와 재현율은 상호 보완적인 평가 지표로 한쪽을 강제로 높이면 다른 하나의 수치가 떨어지기 쉬움  \n",
    "\n",
    "사이킷런의 분류 알고리즘은 예측 데이터가 특정 레이블(Label, 결정 클래스 값)에 속하는지 계산하기 위해, 먼저 개별 레이블별로 결정 확률을 구함 -> 예측 확률이 큰 레이블값으로 예측  \n",
    "\n",
    "사이킷런은 개별 데이터별로 예측 확률을 반환하는 메서드인 predict_proba()를 제공  \n",
    "predict_proba(): 학습 완료된 사이킷런 Classifier 객체에서 호출 가능하며 테스트 피처 데이터 세트를 파라미터로 입력해주면 테스트 피처 레코드의 개별 클래스 예측 확률을 반환 (predict() 메서드와 유사하지만 반환 결과가 예측 결과 클래스 값이 아닌 예측 확률 결과)  \n",
    "\n",
    "이진 분류에서 predict_proba()를 수행해 반환되는 ndarray는 첫 번째 칼럼이 클래스 값 0에 대한 예측 확률, 두 번째 칼럼이 클래스 값 1에 대한 예측 확률  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba() 결과 shape: (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.4623509  0.5376491 ]\n",
      " [0.87875882 0.12124118]\n",
      " [0.87717457 0.12282543]]\n",
      "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.4623509  0.5376491  1.        ]\n",
      " [0.87875882 0.12124118 0.        ]\n",
      " [0.87717457 0.12282543 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba() 결과 shape: {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결괏값 aaray를 병합(concetenate)해 예측 확률과 결괏값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반환 결과인 ndarray는 0과 1에 대한 확률을 나타내므로 첫 번째 칼럼 값과 두 번째 칼럼 값을 더하면 1이 됨  \n",
    "맨 마지막 줄의 predict() 메서드의 결과, 비교에서도 나타나듯이 두 개의 칼럼 중에서 더 큰 확률 값으로 predict() 메서드가 최종 예측  \n",
    "\n",
    "predict() 메서드는 predict_proba() 메서드에 기반해 생성된 API  \n",
    "predict()는 predict_proba() 호출 결과로 반환된 배열에서 분류 결정 임계값보다 큰 값이 들어 있는 칼럼의 위치를 받아서 최종적으로 예측 클래스를 결정하는 API  \n",
    "\n",
    "**코드로 구현해보기**\n",
    "threshold 변수를 특정 값으로 설정하고 Binarizer 클래스를 객체로 생성  \n",
    "-> 생성된 Binarizer 객체의 fit_transform() 메서드를 이용해 넘파이 ndarray를 입력  \n",
    "-> 입력된 ndarray 값이 지정된 threshold보다 같거나 작으면 0 값으로, 크면 1 값으로 변환해 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1, -1, 2],\n",
    "     [2, 0, 0],\n",
    "     [0, 1.1, 1.2]]\n",
    "\n",
    "# X의 개별 원소들이 threshold 값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력된 X 데이터 세트에서 Binarizer의 threshold 값이 1.1보다 같거나 작으면 0, 크면 1로 변환됨을 알 수 있음  \n",
    "\n",
    "Binarizer를 이용해 사이킷런 predict()의 의사(pseudo) 코드 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492\n",
      "정밀도 : 0.7742\n",
      "재현율 : 0.7869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값. 분류 결정 임계값임.\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer 적용\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 의사 코드로 계산된 평가 지표는 앞 예제의 타이타닉 데이터로 학습된 로지스틱 회귀 Classifier 객체에서 호출된 predict()로 계산된 지표 값과 정확히 일치  \n",
    "-> predict()가 predict_proba()에 기반함을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도 : 0.8324\n",
      "정밀도 : 0.7183\n",
      "재현율 : 0.8361\n"
     ]
    }
   ],
   "source": [
    "# 추가. 분류 결정 입계값을 0.5에서 0.4로 낮춰보기\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값. 분류 결정 임계값임. (0.5 -> 0.4)\n",
    "custom_threshold = 0.4\n",
    "\n",
    "# predict_proba() 반환값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer 적용\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임계값을 낮추니 재현율 수치가 올라가고 정밀도가 떨어짐  \n",
    "-> 분류 결정 임계값은 Positive 예측값을 결정하는 확률의 기준  \n",
    "-> 확률을 0.5가 아닌 0.4부터 Positive로 예측을 너그럽게 하여 임계값이 낮아질수록 True 값이 많아짐  \n",
    "\n",
    "Positive 예측값이 많아지면 상대적으로 재현율 값이 높아짐  \n",
    "-> 양성 예측을 많이 하다보니 실제 양성을 음성으로 예측하는 획수가 상대적으로 줄기 때문  \n",
    "\n",
    "<br>\n",
    "임계값을 0.4부터 0.6까지 0.05씩 증가시키며 평가 지표 조사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "임계값:  0.4\n",
      "오차행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도 : 0.8324\n",
      "정밀도 : 0.7183\n",
      "재현율 : 0.8361\n",
      "\n",
      "임계값:  0.45\n",
      "오차행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도 : 0.8492\n",
      "정밀도 : 0.7656\n",
      "재현율 : 0.8033\n",
      "\n",
      "임계값:  0.5\n",
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492\n",
      "정밀도 : 0.7742\n",
      "재현율 : 0.7869\n",
      "\n",
      "임계값:  0.55\n",
      "오차행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도 : 0.8659\n",
      "정밀도 : 0.8364\n",
      "재현율 : 0.7541\n",
      "\n",
      "임계값:  0.6\n",
      "오차행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도 : 0.8771\n",
      "정밀도 : 0.8824\n",
      "재현율 : 0.7377\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 수행할 모든 임계값을 리스트 객체로 저장\n",
    "thresholds = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    #thresholds list 객체 내의 값을 iteration 하면서 평가 수행\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('\\n임계값: ', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1, 1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 임계값 변화에 따른 평가 지표 값을 알아보는 코드를 작성  \n",
    "사이킷런은 이와 유사한 precision_recall_curve() API를 제공  \n",
    "precision_recall_curve() API의 입력 파라미터와 반환 값은 아래와 같음\n",
    "\n",
    "| 입력 파라미터 | y_true: 실제 클래스값 배열(배열 크기 = [데이터 건수], probas_pred: Positive 칼럼의 예측 확률 배열(배열 크기 = [데이터 건수]\n",
    "|     반환값    | 정밀도: 임계값별 정밀도 값을 배열로 반환, 재현율: 임계값별 재현율 값을 배열로 반환  \n",
    "\n",
    "precision_recall_curve()로 타이타닉 예측 모델의 임계값별 정밀도와 재현율 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추출된 임계값 샘플 10개에 해당하는 정밀도 값과 재현율 값을 살펴보면 임계값이 증가할수록 정밀도값은 동시에 높아지나 재현율 값은 낮아짐    \n",
    "precision_recall_curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
